{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import itertools\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "# local imports\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from utils import *\n",
    "from gtv import *\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SST Observations\n",
    "\n",
    "#### Download raw data [here](https://drive.google.com/drive/u/1/folders/1jQ3m8DI0m8Avl5dB3I2AacHuW1ZLWwpw)\n",
    "\n",
    "The file 'SST_Pacific.mat' includes monthly observations of sea surface temperature (in Celsius) over the Pacific Ocean during 01/1940-12/2018, from the COBE SST v2 dataset.\n",
    "\n",
    "Temperature over land is replaced with \"NaN\" values.\n",
    "\n",
    "The Pacific has been defined as:\n",
    "   - Latitudes: 60S-60N\n",
    "   - Longitudes: 80E-280E\n",
    "\n",
    "Particularly, the file 'SST_Pacific.mat' contains: \n",
    "\n",
    "   - 3D matrix 'SST_Pacif': 121 by 201 by 948\n",
    "   - vector 'lat': 121 by 1 which corresponds to the latitudinal points over Pacific \n",
    "   - vector 'lon': 201 by 1 which corresponds to the longitudinal points over Pacific \n",
    "   - 2D matrix 'dates': 948 by 2 which corresponds to the dates  \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .mat file\n",
    "monthly_atmo = {}\n",
    "with h5py.File('../data/SST_pacific.mat') as f:\n",
    "    for k,v in f.items():\n",
    "        monthly_atmo[k] = np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten 3D array to 2D dataframe\n",
    "sst = monthly_atmo['SST_Pacif']\n",
    "obs_lats = monthly_atmo['lat'][0]\n",
    "obs_lons = monthly_atmo['lon'][0]\n",
    "flat_df = flatten_series(sst, obs_lats, obs_lons, 'monthly', 79, 1940)\n",
    "flat_df['var'] = 'sst'\n",
    "flat_df['val'] = flat_df.temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop nulls (over land)\n",
    "df = flat_df\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove seasonal trend\n",
    "sst = df[df['var']=='sst']\n",
    "seasonal = sst.groupby(['lat', 'lon', 'month']).val.agg(['mean', 'std']).reset_index()\n",
    "sst = pd.merge(sst, seasonal, on=['lat', 'lon', 'month'])\n",
    "sst['anomaly'] = (sst['val'] - sst['mean'])/sst['std']\n",
    "sst['val'] = sst['anomaly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate to 10x10 temporal scale, stack into matrix, scale \n",
    "X_obs, fts_obs, mdf_obs = monthly_X(sst, step=10, agg=True, scale=False, max_year=2018)\n",
    "X_obs = preprocessing.scale(signal.detrend(X_obs, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LENS\n",
    "\n",
    "#### Download raw data [here](https://drive.google.com/drive/u/1/folders/1ddwOm4wIt6A8-_y9KxI0OdSTqTamhK8i)\n",
    "\n",
    "The file 'surf_temp.mat' includes monthly data of surface temperature (in Kelvin) over the Pacific Ocean during 01/1920-12/2005, for all 40 ensembles from LENS.\n",
    "\n",
    "The Pacific has been defined as:\n",
    "\n",
    "   - Latitudes: 60S-60N\n",
    "   - Longitudes: 80E-280E\n",
    "   \n",
    "Particularly, the file 'surf_temp.mat' contains: \n",
    "\n",
    "   - 4D matrix 'TS': 128 by 161 by 1032 by 40\n",
    "   - vector 'lat': 128 by 1 which corresponds to the latitudinal points over Pacific \n",
    "   - vector 'lon': 161 by 1 which corresponds to the longitudinal points over Pacific "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .mat file\n",
    "surf_temp = {}\n",
    "with h5py.File('/Users/abbystevens/Downloads/surf_temp.mat', 'r') as f:\n",
    "    for k, v in f.items():\n",
    "        surf_temp[k] = np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 1032, 161, 128)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surf_temp['TS'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we interpolate LENS onto the same grid as the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "lats = surf_temp['lat'][0].copy() #128\n",
    "lons = surf_temp['lon'][0].copy() #161\n",
    "\n",
    "# define grid to interpolate \n",
    "x = lons.copy()\n",
    "y = lats.copy()\n",
    "z = np.arange(surf_temp['TS'].shape[1])\n",
    "\n",
    "# anchor bounds for imputation (quirk of imputation library)\n",
    "x[0] = 79.5\n",
    "y[-1] = 60.5\n",
    "\n",
    "# great grid to interpolate onto\n",
    "pts = np.array([i for i in itertools.product(z, obs_lons, obs_lats)])\n",
    "\n",
    "iLENS = np.zeros((40, z.shape[0], obs_lons.shape[0], obs_lats.shape[0])) #initialize empty array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 1032, 201, 121)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iLENS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "for i in range(40):\n",
    "    if i%10==0: print(i)\n",
    "    lens = surf_temp['TS'][i] # extract ith trajectory\n",
    "    rgi = RegularGridInterpolator((z, x, y), lens) #train interpolator\n",
    "    ilens = rgi(pts).reshape(z.shape[0], obs_lons.shape[0], obs_lats.shape[0]) #interpolate onto new points\n",
    "    iLENS[i] = ilens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "lens = iLENS[0]\n",
    "flat_df = flatten_lens(lens, obs_lats, obs_lons, 1920)\n",
    "Xlens, fts, lens_df = monthly_X(flat_df, step=10, agg=True, scale=False, min_year=1940, max_year=2005)\n",
    "lens_df['trajectory'] = 0\n",
    "for i in range(1, 40):\n",
    "    if i%10==0: print(i)\n",
    "    lens = iLENS[i]\n",
    "    flat_df = flatten_lens(lens, obs_lats, obs_lons, 1920)\n",
    "    X, fts, mdf = monthly_X(flat_df, step=10, agg=True, scale=False, min_year=1940, max_year=2005)\n",
    "    mdf['trajectory'] = i\n",
    "    lens_df = lens_df.append(mdf, ignore_index=True)\n",
    "    Xlens = np.vstack([Xlens, X])\n",
    "# save processed files\n",
    "lens_df.to_csv('../data/lens_df_raw.csv', index=False)\n",
    "pd.DataFrame(Xlens).to_csv('lens_X_raw.csv', index=False)\n",
    "fts_lens = fts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlap LENS and Obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts_lens['ix_lens'] = fts_lens.index\n",
    "fts_obs['ix_obs'] = fts_obs.index\n",
    "fts = pd.merge(fts_lens, fts_obs)\n",
    "\n",
    "# remove some more land\n",
    "land = pd.DataFrame([[-25, 145],[ 35, 115],[45, 265]], columns = ['lat', 'lon'])\n",
    "land['land'] = 1\n",
    "fts = pd.merge(fts, land, how='left')\n",
    "fts = fts[fts.land.isnull()].drop(columns='land')\n",
    "\n",
    "fts = pd.merge(fts_old, fts_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More LENS processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_df = pd.read_csv('../data/lens_df_raw.csv')\n",
    "Xlens = pd.read_csv('lens_X_raw.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove seasonal trend\n",
    "seasonal = lens_df.groupby(['lat', 'lon', 'month', 'trajectory']).val.agg(['mean', 'std']).reset_index()\n",
    "lens_df = pd.merge(lens_df, seasonal, on=['lat', 'lon', 'month', 'trajectory'])\n",
    "lens_df['anomaly'] = (lens_df['val'] - lens_df['mean'])/lens_df['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't remove mean trend\n",
    "t = lens_df[lens_df.trajectory==0]\n",
    "Xlens = np.vstack(t.groupby('year').anomaly.apply(np.array))\n",
    "for i in range(1, 40):\n",
    "    t = lens_df[lens_df.trajectory==i]\n",
    "    Xtmp = np.vstack(t.groupby('year').anomaly.apply(np.array))\n",
    "    Xlens = np.vstack([Xlens, Xtmp])\n",
    "    \n",
    "# do remove mean trend\n",
    "t = lens_df[lens_df.trajectory==0]\n",
    "Xlens_dt = signal.detrend(np.vstack(t.groupby('year').anomaly.apply(np.array)), axis=0)\n",
    "for i in range(1, 40):\n",
    "    t = lens_df[lens_df.trajectory==i]\n",
    "    Xtmp = signal.detrend(np.vstack(t.groupby('year').anomaly.apply(np.array)), axis=0)\n",
    "    Xlens_dt = np.vstack([Xlens_dt, Xtmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Xlens[:, fts.ix_lens]).to_csv('../data/Xlens_new_interpolated.csv', index=False)\n",
    "pd.DataFrame(Xlens_dt[:, fts.ix_lens]).to_csv('../data/Xlens_new_interpolated_dt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
